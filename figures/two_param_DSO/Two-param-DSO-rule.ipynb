{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different versions of the two-parameter DSO rule, WIP\n",
    "\n",
    "inference results analysis cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from consbi.simulators import (\n",
    "    DistanceRuleSimulator, \n",
    "    RuleSimulator, \n",
    "    poisson_glm, \n",
    "    peters_rule_subcellular, \n",
    "    two_param_poisson_glm,\n",
    "    default_rule_linear, \n",
    "    two_param_rule_dependent,\n",
    "    dso_linear_two_param,\n",
    ")\n",
    "from consbi.simulators.poisson_glm import *\n",
    "from consbi.simulators.rule_simulator import *\n",
    "from consbi.simulators import default_rule\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "from sbi.inference import prepare_for_sbi, simulate_for_sbi\n",
    "from sbi.utils import BoxUniform\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('plotting_settings.mplstyle')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prior will be Gaussian for most rules.\n",
    "num_dim = 3\n",
    "prior_scale = 3\n",
    "# prior = MultivariateNormal(torch.ones(num_dim), 0.5 * torch.eye(num_dim))\n",
    "prior = BoxUniform(0.0 * torch.ones(num_dim), 3 * torch.ones(num_dim))\n",
    "xo = np.array([[0.4300, 0.4300, 0.4200, 0.6400, 0.1700, 0.4400, 0.0900]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson GLM\n",
    "\n",
    "The problem is reduced to just 10 neuron-pair-subvolume combinations withtout summary statistics, i.e., the simulator returns the raw synapse counts sampled from a Poisson distribution. Thus, it is fast and tractable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = prior.sample((10000,))\n",
    "x = poisson_glm(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "plt.hist(x.numpy(), density=0)\n",
    "plt.xlabel(\"Counts\")\n",
    "# plt.legend([f\"neuron-pair-volume combi {ii}\" for ii in range(10)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"../data/structural_model\"\n",
    "# set number of neuron pairs sampled from the connectome to mimick experimental settings, e.g., 50\n",
    "num_subsampling_pairs = 50\n",
    "simulator = RuleSimulator(path_to_model, \n",
    "                          rule=default_rule_linear, \n",
    "                          verbose=True, \n",
    "                          num_subsampling_pairs=num_subsampling_pairs,\n",
    "                          prelocate_postall_offset=True,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = 1000\n",
    "num_dim = 3\n",
    "scaling = 0.5\n",
    "# prior = BoxUniform(0.7 * torch.ones(num_dim), 1.6 * torch.ones(num_dim))\n",
    "prior = MultivariateNormal(torch.ones(num_dim), scaling * torch.eye(num_dim))\n",
    "\n",
    "simulator.rule = default_rule\n",
    "\n",
    "def batch_loop_simulator(theta):\n",
    "        \"\"\"Return a batch of simulations by looping over a batch of parameters.\"\"\"\n",
    "        assert theta.ndim > 1, \"Theta must have a batch dimension.\"\n",
    "        # Simulate in loop\n",
    "        xs = list(map(simulator, theta))\n",
    "        # Stack over batch to keep x_shape\n",
    "        return torch.stack(xs).reshape(theta.shape[0], -1)\n",
    "\n",
    "# wrap the simulator to handle batches of parameters\n",
    "batch_simulator, prior = prepare_for_sbi(batch_loop_simulator, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, x = simulate_for_sbi(batch_simulator, prior, num_simulations=num_simulations, \n",
    "                            num_workers=20, \n",
    "                            simulation_batch_size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 7, figsize=(12, 3), gridspec_kw=dict(wspace=0.15))\n",
    "x = x.squeeze()\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00']\n",
    "num_bins = 15\n",
    "data_labels = [r\"L4\", r\"L4SEP\", r\"L4SP\", r\"L4SS\", r\"L5IT\", r\"L5PT\", r\"L6\"]\n",
    "\n",
    "for ii in range(7):\n",
    "    plt.sca(ax[ii])\n",
    "    plt.hist(x[:, ii].numpy(), color=colors[6], bins=np.linspace(0, 1, num_bins), alpha=0.9)\n",
    "    plt.axvline(xo[0, ii], color=\"k\")\n",
    "    plt.xticks(np.linspace(0,1,2))\n",
    "    plt.xlim(0, 1)\n",
    "    ax[ii].spines[\"right\"].set_visible(False)\n",
    "    ax[ii].spines[\"top\"].set_visible(False)\n",
    "    ax[ii].spines[\"left\"].set_visible(False)\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(data_labels[ii])\n",
    "plt.legend([\"measured\", \"simulated \\nfrom prior\"], bbox_to_anchor=(.11, .69), handlelength=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_plot(prior.sample((10000,)), figsize=(18, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prior predictive samples\n",
    "with open(f\"../results/prior_predictive_samples_dso_two_param_N{num_simulations}.p\", \"wb\") as fh: \n",
    "    pickle.dump(dict(theta=theta, x=x), fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.analysis import pairplot, marginal_plot\n",
    "pairplot(x.numpy()[:10000,:], points=xo[0], upper=\"scatter\", figsize=(18, 12), \n",
    "         points_offdiag=dict(marker=\"+\"), \n",
    "         points_colors=[\"k\"]\n",
    "         \n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"prior_predictive.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../results/npe_dso_constrained_2p_uniform0-3_n500000r2x100k.p\"\n",
    "with open(filename, \"rb\") as fh: \n",
    "#     prior, de, *_ = pickle.load(fh).values()\n",
    "    prior, de, posteriors, thos, xos, kwargs, seed = pickle.load(fh).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = BoxUniform(0.2 * torch.ones(2), 1.6 * torch.ones(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posteriors = _[0]\n",
    "sampless = [p.sample((10000,), show_progress_bars=False) for p in posteriors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import SNPE\n",
    "from sbi.analysis import pairplot, sbc\n",
    "from sbi.simulators.simutils import simulate_in_batches\n",
    "posterior = SNPE(prior).build_posterior(de)\n",
    "samples = posterior.sample((10000,), x=xo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pairplot([\n",
    "    prior.sample((10000,)),\n",
    "#     sampless[-1][:10000],\n",
    "#     samples\n",
    "    ] + sampless\n",
    "    ,\n",
    "                   diag=\"hist\", \n",
    "                   upper=\"contour\", \n",
    "                   contour_offdiag=dict(levels=[0.99]),\n",
    "                   hist_diag=dict(bins=20, density=True), \n",
    "                   samples_colors=[\n",
    "                       \"gray\", \n",
    "                       \"C0\", \"C1\", \"C2\", \"C3\", \"C4\"], \n",
    "                   kde_offdiag=dict(bw_method=0.3, num_bins=100),\n",
    "                   scatter_offdiag=dict(s=1, alpha=0.5),\n",
    "                   points=posteriors[-1].map(),\n",
    "#                    limits=[[low, high] for low, high in zip(prior.base_dist.low, prior.base_dist.high)],\n",
    "                   limits=[[-1, 4]*samples.shape[1]],\n",
    "                   figsize=(8, 8));\n",
    "# fig, ax = pairplot([    \n",
    "# #     prior.sample((10000,)),\n",
    "# #     sampless[0][:10000],\n",
    "#     samples\n",
    "#     ],\n",
    "#                    diag=\"kde\", \n",
    "#                    upper=\"kde\", \n",
    "#                    contour_offdiag=dict(levels=[0.99]),\n",
    "#                    hist_diag=dict(bins=25, density=True), \n",
    "#                    samples_colors=[\n",
    "# #                        \"gray\", \n",
    "#                                    \"C0\", \"C1\", \"C2\", \"C3\", \"C4\"], \n",
    "#                    kde_offdiag=dict(bw_method=0.3, num_bins=100),\n",
    "#     scatter_offdiag=dict(s=1, alpha=0.5),\n",
    "#                    fig=fig, axes=ax, \n",
    "#                    limits=[[0.2, 1.6]*samples.shape[1]],\n",
    "#                   );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors[-1].map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(sampless[-1], rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.analysis import run_sbc, sbc_rank_plot, marginal_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/presimulated_dso_constrained_2p_uniform0-3_n500000.p\", \"rb\") as fh:\n",
    "    _, thetas, xs = pickle.load(fh).values()\n",
    "    xs = xs.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posterior predictive samples\n",
    "simulator.rule = default_rule_constrained_two_param\n",
    "# simulator.rule = default_rule\n",
    "\n",
    "def batch_loop_simulator(theta):\n",
    "        \"\"\"Return a batch of simulations by looping over a batch of parameters.\"\"\"\n",
    "        assert theta.ndim > 1, \"Theta must have a batch dimension.\"\n",
    "        # Simulate in loop\n",
    "        xs = list(map(simulator, theta))\n",
    "        # Stack over batch to keep x_shape\n",
    "        return torch.stack(xs)\n",
    "\n",
    "\n",
    "xos = simulate_in_batches(batch_simulator, \n",
    "                          sampless[-1][:1000], \n",
    "#                           samples[:1000],\n",
    "                          sim_batch_size=50, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_plot([\n",
    "        xs[:1000],\n",
    "        xos.squeeze(), \n",
    "              ], \n",
    "    hist_diag=dict(bins=10, histtype=\"step\",),\n",
    "    samples_colors=[\"gray\", \"C0\"],\n",
    "    points_colors=[\"k\"],\n",
    "    labels=data_labels,\n",
    "    density=True,\n",
    "    limits=[[0, 1]*7],\n",
    "    points=xo.squeeze(), figsize=(18, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save with posterior and predictive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, \"wb\") as fh:\n",
    "    pickle.dump(dict(prior=prior, \n",
    "                     de = de, \n",
    "                     posteriors=posteriors, \n",
    "                     sampless = sampless,\n",
    "#                      samples = samples,\n",
    "                     xos = xos,\n",
    "#                      kwargs=_[0],\n",
    "                     kwargs=_[1],\n",
    "                    ), fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sbc_samples = 1000\n",
    "ranks, daps = run_sbc(thetas[:num_sbc_samples], xs[:num_sbc_samples,], posterior=posterior,\n",
    "                      num_workers=1,\n",
    "                      sbc_batch_size=1,\n",
    "                      reduce_fns=posterior.log_prob\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ranks.numpy(), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "sbc_rank_plot(\n",
    "    ranks=ranks,\n",
    "    num_posterior_samples=1000,\n",
    "    plot_type=\"hist\",\n",
    "    num_bins=20,\n",
    "    kwargs=dict(\n",
    "#         fig=fig, \n",
    "#         axes=ax,\n",
    "        figsize=(10, 5),\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
